{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Transmittance/byzantine-numismatic-prj.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWc8qx4Lt4Vn",
        "outputId": "7ef8722d-6022-42cf-a29a-6e0b16a74666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'byzantine-numismatic-prj' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re, sys\n",
        "import shutil\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "74JA2coiqfO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_bbox_any(cell):\n",
        "    s = str(cell)\n",
        "    nums = re.findall(r\"-?\\d+(?:\\.\\d+)?\", s)\n",
        "    if len(nums) >= 4:\n",
        "        x1, y1, x2, y2 = map(float, nums[:4])\n",
        "        return x1, y1, x2, y2\n",
        "    return None\n",
        "\n",
        "def clamp_xyxy(x1, y1, x2, y2, w, h):\n",
        "    x1 = max(0, min(int(round(x1)), w-1))\n",
        "    x2 = max(0, min(int(round(x2)), w-1))\n",
        "    y1 = max(0, min(int(round(y1)), h-1))\n",
        "    y2 = max(0, min(int(round(y2)), h-1))\n",
        "    if x2 <= x1: x2 = min(w-1, x1+1)\n",
        "    if y2 <= y1: y2 = min(h-1, y1+1)\n",
        "    return x1, y1, x2, y2\n",
        "\n",
        "df = pd.read_csv(\"./byzantine-numismatic-prj/main.csv\")\n",
        "\n",
        "# Выходная папка\n",
        "os.makedirs(\"./byzantine-numismatic-prj/images_by_classes\", exist_ok=True)\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    rel_path = str(row[\"Image_path_av\"]).replace(\"\\\\\", \"/\").replace(\"||\", \"__\")\n",
        "\n",
        "    img_path = Path(\"./byzantine-numismatic-prj/parsed_data\") / rel_path\n",
        "\n",
        "    if not img_path.exists():\n",
        "        print(f\"Файл не найден: {img_path}\")\n",
        "        continue\n",
        "\n",
        "    imperor = str(row[\"Imperor\"]).strip()\n",
        "\n",
        "    class_dir = Path(\"./byzantine-numismatic-prj/images_by_classes\") / imperor\n",
        "    class_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    dst_path = class_dir / img_path.name\n",
        "\n",
        "    # Парсим ббоксы\n",
        "    bbox = parse_bbox_any(row.get(\"bbox_av_face\")) if \"bbox_av_face\" in df.columns else None\n",
        "\n",
        "    # Кроп по ббоксу\n",
        "    with Image.open(img_path) as im:\n",
        "        im = im.convert(\"RGB\")\n",
        "        w, h = im.size\n",
        "        x1, y1, x2, y2 = clamp_xyxy(*bbox, w=w, h=h)\n",
        "        im.crop((x1, y1, x2, y2)).save(dst_path)\n",
        "    continue"
      ],
      "metadata": {
        "id": "yG6Fy9eksoSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCBx1NUZ7yy3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40b116d8-f416-44dd-c4b4-62c55b0caa7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Physical GPUs, 1 Logical GPUs\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import seaborn as sns\n",
        "import logging\n",
        "# В utils мы реализуем дополнительные функции для визуализации процессора обучения\n",
        "sys.path.insert(0, './byzantine-numismatic-prj')\n",
        "import importlib, utils\n",
        "# Настраиваем логирование\n",
        "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
        "# Настраиваем стиль графиков\n",
        "sns.set_style('darkgrid')\n",
        "# Проверяем подходит ли наша GPU для tensorflow\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    for gpu in gpus:\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "  except RuntimeError as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Рисует график обучения\n",
        "def tr_plot(tr_data, start_epoch):\n",
        "    #Plot the training and validation data\n",
        "    tacc = tr_data.history['accuracy']\n",
        "    tloss = tr_data.history['loss']\n",
        "    vacc = tr_data.history['val_accuracy']\n",
        "    vloss = tr_data.history['val_loss']\n",
        "    Epoch_count = len(tacc) + start_epoch\n",
        "    Epochs = []\n",
        "    for i in range (start_epoch, Epoch_count):\n",
        "        Epochs.append(i + 1)\n",
        "    index_loss  = np.argmin(vloss)#  this is the epoch with the lowest validation loss\n",
        "    val_lowest  = vloss[index_loss]\n",
        "    index_acc   = np.argmax(vacc)\n",
        "    acc_highest = vacc[index_acc]\n",
        "    plt.style.use('fivethirtyeight')\n",
        "    sc_label = 'Лучшая эпоха= '+ str(index_loss + 1 + start_epoch)\n",
        "    vc_label = 'Лучшая эпоха= '+ str(index_acc  + 1 + start_epoch)\n",
        "    fig,axes=plt.subplots(nrows=1, ncols = 2, figsize = (20,8))\n",
        "    axes[0].plot (Epochs,tloss, 'r', label = 'Потери при обучении')\n",
        "    axes[0].plot (Epochs,vloss,'g',label='Потери при валидации' )\n",
        "    axes[0].scatter (index_loss + 1 + start_epoch,val_lowest, s = 150, c = 'blue', label = sc_label)\n",
        "    axes[0].set_title('Потери при валидации и обучении')\n",
        "    axes[0].set_xlabel('Эпохи')\n",
        "    axes[0].set_ylabel('Потери')\n",
        "    axes[0].legend()\n",
        "    axes[1].plot (Epochs,tacc,'r', label = 'Точность при обучении')\n",
        "    axes[1].plot (Epochs,vacc,'g', label = 'Точность при валидации')\n",
        "    axes[1].scatter(index_acc + 1 + start_epoch, acc_highest, s = 150, c = 'blue', label = vc_label)\n",
        "    axes[1].set_title  ('Точность при валидации и обучении')\n",
        "    axes[1].set_xlabel ('Эпохи')\n",
        "    axes[1].set_ylabel ('Точность')\n",
        "    axes[1].legend()\n",
        "    plt.tight_layout\n",
        "    #plt.style.use('fivethirtyeight')\n",
        "    plt.show()\n",
        "# Создаем data_frame, в котором название папки является меткой класса изображений (коты и собаки в нашем случае)\n",
        "# Каждому элементу data_frame будет присвоена метка (DX) и название файла (image)\n",
        "# Функция возвращает объект frame\n",
        "def load_data_frame(sdir):\n",
        "    classlist = os.listdir(sdir)\n",
        "    filepaths = []\n",
        "    labels = []\n",
        "    for klass in classlist:\n",
        "        classpath=os.path.join(sdir, klass)\n",
        "        flist=os.listdir(classpath)\n",
        "        for f in flist:\n",
        "            fpath = os.path.join(classpath, f)\n",
        "            filepaths.append( fpath.replace('\\\\', '/') )\n",
        "            labels.append(klass)\n",
        "\n",
        "    Fseries=pd.Series( filepaths, name = 'image' )\n",
        "    Lseries=pd.Series(labels, name = 'dx')\n",
        "    return pd.concat([Fseries, Lseries], axis=1)"
      ],
      "metadata": {
        "id": "zkqiLyjx_aV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Размер картинки для подачи в модели\n",
        "height   = 224\n",
        "width    = 224\n",
        "channels = 3\n",
        "\n",
        "# Размер пачки для обучения\n",
        "batch_size = 20\n",
        "# Размер пачки для валидации\n",
        "test_batch_size = 50\n",
        "\n",
        "# Инициализаци рандом: None - всегда рандом, Число - повторяемый рандом\n",
        "my_random = None\n",
        "\n",
        "# Загружаем сгенерированные картинки (картинка должны лежать по папкам с названием их DX)\n",
        "df2 = load_data_frame (\"./byzantine-numismatic-prj/images_by_classes/\")\n",
        "\n",
        "# Разделяем выборку на обучающую, тестовую и валидационную (случайным образом)\n",
        "train_df, test_df = train_test_split (df2, train_size= .9, shuffle = True, random_state = my_random)\n",
        "valid_df, test_df = train_test_split (test_df, train_size= .5, shuffle = True, random_state = my_random)\n",
        "\n",
        "# Задаем параметры входящей картинки\n",
        "img_shape = (height, width, channels)\n",
        "img_size  = (height, width)\n",
        "length    = len(test_df)\n",
        "\n",
        "# выводим найденное число n\n",
        "test_steps = int(length/test_batch_size)\n",
        "print ( 'test batch size: ' ,test_batch_size, '  test steps: ', test_steps)\n",
        "\n",
        "# C помощью ImageDataGenerator () можно аугментировать изображения прямо во время обучения, но аугментация — это отдельная тема\n",
        "trgen = ImageDataGenerator()\n",
        "\n",
        "# Генератор для тестовой выборки\n",
        "tvgen = ImageDataGenerator()\n",
        "\n",
        "# Выборка для обучения модели\n",
        "train_gen = trgen.flow_from_dataframe ( train_df, directory = None, x_col = \"image\", y_col = \"dx\", target_size = img_size, class_mode = 'categorical',\n",
        "                                    color_mode='rgb', shuffle=True, batch_size=batch_size)\n",
        "\n",
        "# Выборка для тестирования сети после обучения\n",
        "test_gen = tvgen.flow_from_dataframe ( test_df, directory = None, x_col= \"image\", y_col = \"dx\", target_size = img_size, class_mode = 'categorical',\n",
        "                                    color_mode='rgb', shuffle=False, batch_size=test_batch_size)\n",
        "# Выборка для тестирования сети во время обучения\n",
        "valid_gen = tvgen.flow_from_dataframe ( valid_df, directory = None, x_col=\"image\", y_col = \"dx\", target_size = img_size, class_mode = 'categorical',\n",
        "                                    color_mode='rgb', shuffle = True, batch_size = batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXFLIUsugy72",
        "outputId": "990ea9f9-4f5b-4de5-e5eb-4b2cce18da2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test batch size:  50   test steps:  0\n",
            "Found 701 validated image filenames belonging to 3 classes.\n",
            "Found 39 validated image filenames belonging to 3 classes.\n",
            "Found 39 validated image filenames belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Получаем метки классов\n",
        "classes     = list (train_gen.class_indices.keys())\n",
        "class_count = len(classes)\n",
        "train_steps = np.ceil(len(train_gen.labels)/batch_size)\n",
        "# Задаем имя модели\n",
        "model_name = 'EfficientNetB3'\n",
        "# Генерируем экземпляр модели EfficientNetB3\n",
        "base_model = tf.keras.applications.EfficientNetB3(include_top = False, weights = \"imagenet\", input_shape = img_shape, pooling = 'max')\n",
        "# Создаем выходной слой\n",
        "x = base_model.output\n",
        "x = tf.keras.layers.BatchNormalization(axis = -1, momentum = 0.99, epsilon = 0.001 )(x)\n",
        "x = Dense(256, kernel_regularizer = regularizers.l2(0.016), activity_regularizer = regularizers.l1(0.006),\n",
        "                bias_regularizer = regularizers.l1(0.006), activation = 'relu')(x)\n",
        "x = Dropout(rate = .45, seed = my_random)(x)\n",
        "#Создаем выходной полносвязный слой и присоединяем его к предыдущим слоям (количество нейронов совпадает с количеством классов\n",
        "output = Dense(class_count, activation = 'softmax')(x)\n",
        "# Собираем модель вместе\n",
        "model = Model(inputs = base_model.input, outputs = output)\n",
        "# Компилируем модель\n",
        "model.compile(Adamax(learning_rate = 0.001), loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "YmfPtjnQvKQR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbc61ff7-f3c9-4cab-ee6e-6f5badca298c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n",
            "\u001b[1m43941136/43941136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Задаем параметры обучения\n",
        "epochs        = 15 # Количество эпох\n",
        "patience      = 1 # количество эпох, в течение которых необходимо отрегулировать lr, если отслеживаемое значение не улучшится\n",
        "stop_patience = 6 # количество эпох ожидания перед остановкой обучения, если отслеживаемое значение не улучшится\n",
        "threshold     = .9\n",
        "factor        = .5\n",
        "dwell         = True # если True и отслеживаемая метрика не улучшаются по сравнению с текущей эпохой, возвращают веса модели к весам предыдущей эпохи.\n",
        "freeze        = False #\n",
        "ask_epoch     = 10 # количество эпох, которые нужно выполнить, прежде чем спросить, хотите ли вы остановить обучение\n",
        "batches       = train_steps\n",
        "\n",
        "# utils.LRA реализует вывод информации прямо в процессе обучения\n",
        "#  Об этом стоит рассказать подробнее, но это тема для отдельной статьи\n",
        "callbacks = [utils.LRA(model = None,\n",
        "                       base_model = base_model,\n",
        "                       patience=patience,\n",
        "                       stop_patience = stop_patience,\n",
        "                       threshold = threshold,\n",
        "                       factor = factor,\n",
        "                       dwell = dwell,\n",
        "                       batches = batches,\n",
        "                       initial_epoch = 0,\n",
        "                       epochs = epochs,\n",
        "                       ask_epoch = ask_epoch )]\n",
        "# Запускаем обучение модели и сохраняем историю обучения\n",
        "history = model.fit (x = train_gen,  epochs = epochs, verbose = 0, callbacks = callbacks,  validation_data = valid_gen, validation_steps = None,  shuffle = False,  initial_epoch = 0)\n",
        "\n",
        "# Рисуем график обучения и выводим\n",
        "tr_plot(history,0)\n",
        "# Проверяем точность модели на тестовой выборке и выводим результат тестирования\n",
        "save_dir = './'\n",
        "subject = 'Imperors'\n",
        "\n",
        "acc = model.evaluate( test_gen, batch_size = test_batch_size, verbose = 1, steps=test_steps, return_dict = False)[1]*100\n",
        "msg = f'accuracy on the test set is {acc:5.2f} %'\n",
        "utils.print_in_color(msg, (0,255,0),(55,65,80))\n",
        "\n",
        "# Сохраняем модель в файл, его потом можно загрузить и использовать без обучения для классификации изображений\n",
        "save_id   = str (model_name +  '-' + subject +'-'+ str(acc)[:str(acc).rfind('.')+3] + '.h5')\n",
        "save_loc  = os.path.join(save_dir, save_id)\n",
        "model.save(save_loc)\n",
        "generator = train_gen\n",
        "scale     = 1\n",
        "result    = utils.saver(save_dir, model, model_name, subject, acc, img_size, scale,  generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "id": "CXcM8jMpwZ4y",
        "outputId": "2f8dc628-557e-4cfb-be75-32ea503186f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;2;244;252;3;48;2;55;65;80minitializing callback starting train with base_model trainable\n",
            "\u001b[0m\n",
            "\u001b[38;2;244;252;3;48;2;55;65;80m Epoch     Loss   Accuracy  V_loss    V_acc     LR     Next LR  Monitor  Duration\n",
            "\u001b[0m\n",
            "\u001b[38;2;0;255;0;48;2;55;65;80m 1 /15    17.454   60.342  17.38607  48.718   0.00100  0.00100  accuracy   216.02 \n",
            "\u001b[0m\n",
            "\u001b[38;2;0;255;0;48;2;55;65;80m 2 /15     8.110   65.050   8.09820  46.154   0.00100  0.00100  accuracy    6.01  \n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'name'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-540441819.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m                        ask_epoch = ask_epoch )]\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Запускаем обучение модели и сохраняем историю обучения\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0minitial_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Рисуем график обучения и выводим\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/byzantine-numismatic-prj/utils.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    244\u001b[0m                     \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m245\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m170\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m66\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m                     \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m                     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'name'"
          ]
        }
      ]
    }
  ]
}